=== Model Evaluation Results ===

Accuracy: 0.4500
Precision (macro): 0.3250
Recall (macro): 0.3257
F1 Score (macro): 0.3179
F1 Score (weighted): 0.4436

Confusion Matrix:
[[3 0 2 0 2]
 [1 0 0 0 0]
 [1 0 0 0 1]
 [0 0 0 3 2]
 [1 0 0 1 3]]

Classification Report:
              precision    recall  f1-score   support

           1       0.50      0.43      0.46         7
           2       0.00      0.00      0.00         1
           3       0.00      0.00      0.00         2
           4       0.75      0.60      0.67         5
           5       0.38      0.60      0.46         5

    accuracy                           0.45        20
   macro avg       0.33      0.33      0.32        20
weighted avg       0.46      0.45      0.44        20
